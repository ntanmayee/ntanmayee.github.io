I"u<p><em>This post is a brief summary of Judea Pearl’s paper “Theoretical Impediments to Machine Learning With Seven Sparks from the Causal Revolution” [<a href="https://arxiv.org/abs/1801.04016">arxiv</a>]</em> <!--more--></p>

<hr />

<p>What more do we need in order to reach a stage where Artificial Intelligence rivals human intelligence?</p>

<p>Consider an eagle’s eyesight - its vision system has evolved over a period of millions of years, by taking in a stream of sensory inputs and optimizing its performance.</p>

<p>This is Darwin’s evolutionary process at work, and it’s slow. Most machine learning algorithms operate in this way.</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/Golden_Eagle_eye.jpg/512px-Golden_Eagle_eye.jpg" alt="Eagle" /></p>
<figcaption class="caption">The Eye of a Golden Eagle (Wikimedia Commmons)</figcaption>
<p><br /></p>

<p>On the other hand, humans were able to invent telescopes and microscopes in a few thousands of years, which rival or surpass the best vision systems found in nature.</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/98/12.6%22_Fitz_telescope_in_Ann_Arbor.jpg/512px-12.6%22_Fitz_telescope_in_Ann_Arbor.jpg" alt="Telescope" /></p>
<figcaption class="caption">The Fitz Telescope at Ann Arbor (Wikimedia Commmons)</figcaption>
<p><br /></p>

<p><strong>How did this super-evolutionary process happen?</strong></p>

<p>Pearl argues that this was possible because humans have a “blueprint of the environment”, a mental model of how things work, and this helps in imagining alternate universes and hypothetical situations that have not actually happened.</p>

<p>How might we build a system that can answer retrospective, hypothetical “what-if” questions? According to Pearl, just data is not enough, and model-driven reasoning is necessary for strong AI.</p>

<h3 id="the-causal-hierarchy">The Causal Hierarchy</h3>
<p>Causal theory helps in classifying information into a three level hierarchy. This sharp categorization helps in reasoning over the nature of information required to answer questions from a certain level. Questions at a particular level can be answered only if information from successive levels are available.</p>

<p><img src="https://raw.githubusercontent.com/triptoes1/triptoes1.github.io/master/assets/images/causal-hierarchy.png" alt="Causal Hierarchy" /></p>

<ol>
  <li>Association questions are inferred from just data, and nothing more.</li>
  <li>Intervention questions involve changing what is observed.</li>
  <li>Counterfactual questions are retrospective, they ask what would have happened if we had made a change.</li>
</ol>

<p>Counterfactual questions subsume association and intervention questions.</p>

<p>Structural Causal Models (SCM) can answer counterfactual questions. Hence, they have the capacity to answer even intervention and association questions. The theory of Structural Causal Models allows us to formally codify background knowledge, and warns about the limitations of methods that only use data for estimation. Basically, certain classes of questions (specifically interventions and counterfactuals) cannot be answered from data alone.</p>

<h3 id="scm-inference-engine">SCM Inference Engine</h3>
<p><img src="https://raw.githubusercontent.com/triptoes1/triptoes1.github.io/master/assets/images/scm-inference-engine.png" alt="SCM Engine" /></p>

<p>If we were to build an inference engine using SCM, it would look like this -</p>

<ol>
  <li>Inputs:
    <ul>
      <li>Query, which is the question that needs to be answered</li>
      <li>Assumptions, which are usually codified by a directed graph</li>
      <li>Data</li>
    </ul>
  </li>
  <li>Outputs:
    <ul>
      <li>Estimand is a recipe or formula to answer the query based on assumptions</li>
      <li>Estimate is the answer to the query, which is computed from the estimand and the data</li>
      <li>Fit indices are a measure of compatibility between the data and the assumptions</li>
    </ul>
  </li>
</ol>

<h3 id="conclusion">Conclusion</h3>
<p>There are theoretical limitations to the kinds of questions that can be answered from data alone. It is worthwhile to explore if model-driven reasoning is the missing link to human level artificial intelligence. As Pearl says -</p>

<blockquote>
  <p>Data alone are hardly a science, regardless how big they get and how skillfully they are manipulated.</p>
</blockquote>
:ET